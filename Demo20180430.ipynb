{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series and DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([['frank', 'M', 29], ['mary', 'F', 23], ['tom', 'M', 35], ['ted', 'M', 33], ['jean', 'F', 21], ['lisa', 'F', 20]])\n",
    "\n",
    "df.columns = ['name', 'gender', 'age']\n",
    "df\n",
    "\n",
    "\n",
    "s = pd.Series([11, 22, 33, 44, 55])\n",
    "s\n",
    "\n",
    "s.max()\n",
    "s.min()\n",
    "s.mean()\n",
    "s.describe()\n",
    "\n",
    "s[2]\n",
    "s[2:4]\n",
    "\n",
    "s.index = ['a', 'b', 'c', 'd', 'e']\n",
    "s\n",
    "\n",
    "s['c']\n",
    "\n",
    "age  = pd.Series([22,34,42])\n",
    "name = pd.Series(['mary', 'toby', 'sherry'])\n",
    "\n",
    "pd.DataFrame([name, age]).T\n",
    "\n",
    "\n",
    "df = pd.DataFrame([['frank', 'M', 29], ['mary', 'F', 23], ['tom', 'M', 35], ['ted', 'M', 33], ['jean', 'F', 21], ['lisa', 'F', 20]])\n",
    "\n",
    "df.columns = ['name', 'gender', 'age'] \n",
    "df\n",
    "\n",
    "df.describe()\n",
    "df.ix[1]\n",
    "\n",
    "df.ix[1:4]\n",
    "\n",
    "df[['name', 'age']]\n",
    "\n",
    "\n",
    "df['gender'] == 'M'\n",
    "df[df['gender'] == 'M']\n",
    "\n",
    "df[df['gender'] == 'M'].mean()\n",
    "df[df['gender'] == 'F'].mean()\n",
    "\n",
    "df.groupby('gender')['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.sql import SQLContext \n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "\n",
    "data_file = \"file:///tmp/ratings.txt\" \n",
    "raw_data = sc.textFile(data_file)\n",
    "raw_data.take(3)\n",
    "\n",
    "header = raw_data.first()\n",
    "header\n",
    "\n",
    "skip_data = raw_data.filter(lambda line: line != header)\n",
    "skip_data.take(3)\n",
    "\n",
    "csv_data = skip_data.map(lambda l: l.split('::'))\n",
    "csv_data.take(3)\n",
    "\n",
    "from pyspark.sql import Row\n",
    "row_data = csv_data.map(lambda p: Row(\n",
    "   userid = p[0],\n",
    "   itemid = p[1],\n",
    "   rating = int(p[2])\n",
    ")\n",
    ")\n",
    "row_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark DataFrame 操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "df = sqlContext.createDataFrame(row_data)\n",
    "#df.show(5)\n",
    "#df.take(5)\n",
    "# select itemid, rating from df where rating >= 4 limit 5\n",
    "df.filter('rating >= 4').select('itemid', 'rating').show(5)\n",
    "df.select('userid','rating').groupBy('userid').avg().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "df.registerTempTable(\"ratings\")\n",
    "#df.printSchema()\n",
    "ratings_data = sqlContext.sql(\"\"\"\n",
    "SELECT itemid,avg(rating) as avg_rating from ratings group by itemid order by avg(rating) desc limit 5\n",
    "\"\"\")\n",
    "ratings_data.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將 Spark DataFrame 轉換為 rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_out  = ratings_data.rdd.map(lambda e: 'itemid: {}, rating: {}'.format(e.itemid, e.avg_rating))\n",
    "rating_out.take(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將 Spark DataFrame 轉換為 Pandas DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = ratings_data.toPandas()\n",
    "pandas_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
